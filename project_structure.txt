cheating_detection_app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI entrypoint
â”‚   â”œâ”€â”€ webrtc_handler.py    # WebRTC frame receiver and dispatcher
â”‚   â”œâ”€â”€ yolo_detector.py     # YOLOv12 detection logic
â”‚   â”œâ”€â”€ head_pose.py         # MediaPipe head pose logic
â”‚   â”œâ”€â”€ logger.py            # Central logging utility
|   â”œâ”€â”€ detectors.py         # Combination of yolo_detector+head_pose+logger
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css            # Frontend styles
â”‚   â””â”€â”€ script.js            # JavaScript for WebRTC
â”œâ”€â”€ templates/
|   â””â”€â”€ index.html           # WebRTC frontend page
â”œâ”€â”€ detection_log.txt        # Output logs
â”œâ”€â”€ requirements.txt         # Project dependencies
â””â”€â”€ README.md                # Documentation


âœ… Step-by-step coding order (high-level):
main.py (FastAPI entry point)
â†’ Set up the FastAPI server and basic routes.

webrtc_handler.py
â†’ Handle receiving video frames via WebRTC (e.g., using aiortc).

yolo_detector.py and head_pose.py
â†’ Implement model inference functions (load model, detect objects/head pose).

detection_pipeline.py (optional)
â†’ Merge logic from YOLO + head pose + logging in one processing function.

Frontend WebRTC code (frontend/static/js/)
â†’ Use JavaScript + WebRTC to send webcam feed to the backend.

Logging setup
â†’ Finalize how logs are appended (e.g., detection_log.txt).

ðŸ§  Why this order?
Start with the API skeleton.

Then build the data transport (WebRTC).

Then develop the detection logic.

Finally, connect everything together.

Data flow Summary

[User Browser]
    |
    |  getUserMedia + WebRTC
    â–¼
[WebRTC Client JS]
    |
    |  MediaStream (video) â†’ WebRTC
    â–¼
[Backend (Python + aiortc)]
    |
    |  Extract video frames (numpy)
    â–¼
[Detection Pipeline (YOLO + MediaPipe)]
    |
    |  Logging
    â–¼
[detection_log.txt]